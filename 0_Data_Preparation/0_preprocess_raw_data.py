# =============================================================================
# ğŸ§¹ Step 0: Preprocessing (The Mixed Data Strategy)
# æ ¸å¿ƒæ”¹åŠ¨ï¼šä¸å†è¿‡æ»¤æ—  KG çš„ç‰©å“ï¼ä¿ç•™å™ªéŸ³ï¼Œå¢åŠ éš¾åº¦ã€‚
# =============================================================================

import os
import pandas as pd
import numpy as np
import re

def setup_project_paths():
    try: current_path = os.path.dirname(os.path.abspath(__file__))
    except: current_path = os.getcwd()
    check_path = current_path
    for _ in range(3):
        if os.path.exists(os.path.join(check_path, 'data')): return check_path
        parent = os.path.dirname(check_path)
        if parent == check_path: break
        check_path = parent
    return current_path

PROJECT_ROOT = setup_project_paths()
DATA_DIR = os.path.join(PROJECT_ROOT, 'data')
DATASET_DIR = os.path.join(PROJECT_ROOT, 'dataset', 'MOOCCubeX')
INPUT_CSV = os.path.join(DATA_DIR, 'mooccubex_cleaned_data.csv')
OUTPUT_INTER = os.path.join(DATASET_DIR, 'MOOCCubeX.inter')

def preprocess_mixed_data():
    print(f"ğŸ“‚ Project Root: {PROJECT_ROOT}")
    print(f"ğŸ“– è¯»å–äº¤äº’ CSV: {INPUT_CSV} ...")
    
    # 1. è¯»å–åŸå§‹æ•°æ®
    df = pd.read_csv(INPUT_CSV)
    df.columns = df.columns.str.strip()
    
    # 2. è¯†åˆ«åˆ—å
    cols = df.columns
    uid_col = next((c for c in cols if c in ['user_id', 'userId']), cols[0])
    iid_col = next((c for c in cols if c in ['item_id', 'problem_id']), cols[1])
    ts_col = next((c for c in cols if c in ['timestamp', 'time', 'submit_time']), cols[-1])
    
    print(f"   ğŸ“Š åŸå§‹äº¤äº’æ•°: {len(df)}")

    # 3. ID è§„æ•´åŒ– (ç»Ÿä¸€è½¬ä¸ºçº¯æ•°å­—å­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿åç»­åŒ¹é…ï¼Œä½†ä¸è¿‡æ»¤)
    print("   ğŸ”§ è§„æ•´åŒ– Item ID (æå–æ•°å­—)...")
    def extract_id_from_csv(x):
        nums = re.findall(r'\d+', str(x))
        return nums[0] if nums else str(x) # æ‰¾ä¸åˆ°æ•°å­—å°±ä¿ç•™åŸæ ·
    
    df[iid_col] = df[iid_col].apply(extract_id_from_csv)
    
    # ğŸ”¥ å…³é”®ç‚¹ï¼šè¿™é‡Œä¸å†åŠ è½½ KG è¿›è¡Œè¿‡æ»¤ï¼æˆ‘ä»¬ä¿ç•™æ‰€æœ‰ç‰©å“ï¼ ğŸ”¥
    # è¿™æ · SASRec å°±è¦é¢å¯¹å¤§é‡å®ƒâ€œçœ‹ä¸æ‡‚â€çš„å†·é—¨ç‰©å“äº†ã€‚
    
    # 4. å†·å¯åŠ¨æˆªæ–­ (ä¿ç•™å‰ 8 æ¡)
    print("   â³ æŒ‰æ—¶é—´æ’åºå¹¶æ‰§è¡Œã€True Cold-Startã€‘æˆªæ–­ (Top 8)...")
    try: df[ts_col] = pd.to_numeric(df[ts_col], errors='raise')
    except: df[ts_col] = pd.to_datetime(df[ts_col]).astype('int64') // 10**9
    
    # å»é‡
    df.drop_duplicates(subset=[uid_col, iid_col], keep='first', inplace=True)
    
    # æ’åº
    df = df.sort_values(by=[uid_col, ts_col])
    
    # æˆªæ–­
    KEEP_N = 8
    df_cold = df.groupby(uid_col).head(KEEP_N).reset_index(drop=True)
    
    # è¿‡æ»¤è¿‡çŸ­ç”¨æˆ· (è‡³å°‘ 5 æ¡ï¼Œä¿è¯åŸºæœ¬è®­ç»ƒ)
    user_counts = df_cold[uid_col].value_counts()
    valid_users = user_counts[user_counts >= 5].index
    df_cold = df_cold[df_cold[uid_col].isin(valid_users)]
    
    print(f"   ğŸ“‰ æœ€ç»ˆè¡Œæ•°: {len(df_cold)}")
    print(f"   ğŸ‘¥ å‰©ä½™ç”¨æˆ·: {df_cold[uid_col].nunique()}")
    print(f"   ğŸ“¦ å‰©ä½™ç‰©å“: {df_cold[iid_col].nunique()} (åŒ…å«æ—  KG ç‰©å“)")

    # 5. ä¿å­˜
    os.makedirs(os.path.dirname(OUTPUT_INTER), exist_ok=True)
    df_inter = df_cold[[uid_col, iid_col, ts_col]].copy()
    df_inter.columns = ['user_id:token', 'item_id:token', 'timestamp:float']
    
    df_inter.to_csv(OUTPUT_INTER, sep='\t', index=False)
    print(f"   âœ… æ··åˆæ•°æ®é›†ç”Ÿæˆå®Œæ¯•: {OUTPUT_INTER}")

if __name__ == "__main__":
    preprocess_mixed_data()