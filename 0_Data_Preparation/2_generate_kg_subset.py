# =============================================================================
# ğŸ”— Step 2: Generate KG Subset (Synced with .inter)
# ç›®çš„ï¼šæ ¹æ® MOOCCubeX.inter ä¸­å®é™…å‡ºç°çš„ç‰©å“ï¼Œæå–å¯¹åº”çš„ KG å­é›†
# ä¿®å¤ï¼šç›´æ¥è¯»å– .inter æ–‡ä»¶ï¼Œç¡®ä¿ KG ä¸å†·å¯åŠ¨æˆªæ–­åçš„æ•°æ® 100% å¯¹é½
# =============================================================================

import os
import pickle
import pandas as pd
import numpy as np
import re
from tqdm import tqdm

def setup_paths():
    try: current_path = os.path.dirname(os.path.abspath(__file__))
    except: current_path = os.getcwd()
    check_path = current_path
    for _ in range(3):
        if os.path.exists(os.path.join(check_path, 'data')): return check_path
        parent = os.path.dirname(check_path)
        if parent == check_path: break
        check_path = parent
    return current_path

PROJECT_ROOT = setup_paths()
DATA_DIR = os.path.join(PROJECT_ROOT, 'data')
# è¯»å–åˆšæ‰ç”Ÿæˆçš„ .inter æ–‡ä»¶
INTER_PATH = os.path.join(PROJECT_ROOT, 'dataset', 'MOOCCubeX', 'MOOCCubeX.inter')
# KG è¾“å‡ºç›®å½•
OUTPUT_DIR = os.path.join(PROJECT_ROOT, 'dataset', 'MOOCCubeX_KG_Only')
KG_SOURCE = os.path.join(DATA_DIR, 'kg_data.pkl')

def generate_kg_subset():
    print(f"ğŸ“‚ Project Root: {PROJECT_ROOT}")
    print("ğŸ”— Generating KG Subset synced with Interaction Data...")
    
    # 1. è¯»å– .inter æ–‡ä»¶ (è¿™æ˜¯å”¯ä¸€çš„çœŸç†æ¥æº)
    if not os.path.exists(INTER_PATH):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° {INTER_PATH}")
        print("   è¯·å…ˆè¿è¡Œ 0_preprocess_raw_data.py ç”Ÿæˆæˆªæ–­åçš„æ•°æ®ã€‚")
        return

    print(f"ğŸ“– è¯»å–äº¤äº’æ•°æ®: {INTER_PATH} ...")
    df_inter = pd.read_csv(INTER_PATH, sep='\t')
    
    # è·å–æ‰€æœ‰æ´»è·ƒçš„ item_id
    # åˆ—åé€šå¸¸æ˜¯ 'item_id:token'
    iid_col = [c for c in df_inter.columns if 'item_id' in c][0]
    active_items = set(df_inter[iid_col].unique())
    
    print(f"   ğŸ“Š äº¤äº’æ•°æ®ä¸­åŒ…å« {len(active_items)} ä¸ªå”¯ä¸€ç‰©å“")

    # 2. åŠ è½½åŸå§‹ KG
    print(f"ğŸ“¦ åŠ è½½åŸå§‹ KG: {KG_SOURCE} ...")
    if not os.path.exists(KG_SOURCE):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°åŸå§‹ KG æ–‡ä»¶ {KG_SOURCE}")
        return

    with open(KG_SOURCE, 'rb') as f:
        raw_kg = pickle.load(f)
    
    # å…¼å®¹å¤„ç†ï¼šæœ‰äº› kg_data æ˜¯ dict, æœ‰äº›ç›´æ¥æ˜¯æ˜ å°„
    item2concept = raw_kg.get('item2concept', raw_kg) if isinstance(raw_kg, dict) else raw_kg
    
    # 3. è¿‡æ»¤ KG (åªä¿ç•™ active_items é‡Œçš„)
    print("   âœ‚ï¸ æ­£åœ¨è¿‡æ»¤ KG...")
    
    filtered_kg = {}
    hit_count = 0
    
    def extract_id(s):
        # ä» '123' æˆ– 'item_123' ä¸­æå–æ•°å­—
        nums = re.findall(r'\d+', str(s))
        return int(nums[0]) if nums else None

    # å»ºç«‹æ˜ å°„åŠ é€ŸæŸ¥æ‰¾
    # æ³¨æ„ï¼š.inter é‡Œçš„ item_id å¯èƒ½æ˜¯ int ä¹Ÿå¯èƒ½æ˜¯ str
    # æˆ‘ä»¬ç»Ÿä¸€è½¬ä¸º int è¿›è¡Œæ¯”å¯¹
    active_ids_int = set()
    for iid in active_items:
        d = extract_id(iid)
        if d is not None: active_ids_int.add(d)

    for k, concepts in tqdm(item2concept.items(), desc="Filtering"):
        item_id = extract_id(k)
        if item_id in active_ids_int:
            filtered_kg[k] = concepts
            hit_count += 1
            
    print(f"   âœ… KG è¿‡æ»¤å®Œæˆ: åŸæœ‰ {len(item2concept)} -> ç°æœ‰ {len(filtered_kg)}")
    print(f"   ğŸ“‰ è¦†ç›–ç‡: {hit_count / len(active_items) * 100:.2f}% çš„ç‰©å“æ‹¥æœ‰ KG ä¿¡æ¯")

    # 4. ä¿å­˜æ–°çš„ KG å­é›†
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # ä¿å­˜ pkl (ç»™æ¨¡å‹åŠ è½½ç”¨)
    # ä¸ºäº†å…¼å®¹æ—§ä»£ç ï¼Œæˆ‘ä»¬æ›´æ–°åŸæ–‡ä»¶é‡Œçš„ item2concept éƒ¨åˆ†
    new_kg_data = {'item2concept': filtered_kg}
    # å¦‚æœåŸå§‹æ•°æ®é‡Œæœ‰åˆ«çš„è¡¨ï¼ˆå¦‚ concept2instructionï¼‰ï¼Œä¹Ÿå¯ä»¥é€‰æ‹©ä¿ç•™æˆ–ä¸¢å¼ƒ
    # è¿™é‡Œæˆ‘ä»¬åªä¿ç•™æœ€æ ¸å¿ƒçš„ item2concept ä»¥èŠ‚çœç©ºé—´
    
    out_pkl = os.path.join(DATA_DIR, 'kg_data.pkl') # æ³¨æ„ï¼šè¿™é‡Œä¸ºäº†æ–¹ä¾¿ï¼Œæˆ‘ä»¬å…¶å®ä¸ç”¨è¦†ç›–åŸå§‹æ•°æ®ï¼Œä½†æ¨¡å‹è¯»å–è·¯å¾„é€šå¸¸æ˜¯å›ºå®šçš„
    # ä¸ºäº†ä¸ç ´ååŸå§‹æ•°æ®ï¼Œæˆ‘ä»¬å­˜åˆ° dataset ç›®å½•ä¸‹ï¼Œä½†éœ€è¦ç¡®è®¤ä½ çš„æ¨¡å‹è¯»å–é€»è¾‘
    # ä½ çš„æ¨¡å‹ä»£ç é‡Œå†™çš„æ˜¯: kg_path = os.path.join(DATA_DIR, 'kg_data.pkl')
    # æ‰€ä»¥æˆ‘ä»¬å¾—å°å¿ƒã€‚
    
    # ğŸ’¡ æœ€ä½³å®è·µï¼š
    # æ—¢ç„¶æ˜¯ "Subset"ï¼Œæˆ‘ä»¬åº”è¯¥ç”Ÿæˆå¯¹åº”çš„ .kg æ–‡ä»¶ç»™ RecBole ç”¨ï¼Œ
    # æˆ–è€…ç”Ÿæˆä¸€ä¸ªæ–°çš„ pkl ç»™ä½ çš„æ¨¡å‹ç”¨ã€‚
    # ä½ çš„æ¨¡å‹ä»£ç  (3_exp...) è¯»å–çš„æ˜¯ DATA_DIR/kg_data.pklã€‚
    # ä¸ºäº†ä¸å½±å“å…¶ä»–å®éªŒï¼Œæˆ‘ä»¬ä¸è¦è¦†ç›– data/kg_data.pklã€‚
    # 
    # ä½†æ˜¯ï¼ä½ çš„ 3_exp ä»£ç æ˜¯å†™æ­»çš„è¯»å– data/kg_data.pklã€‚
    # ä¸ºäº†é€»è¾‘é—­ç¯ï¼Œæˆ‘ä»¬è¿™é‡Œè¿˜æ˜¯**ä¸è¦†ç›–**åŸå§‹æ–‡ä»¶ï¼Œè€Œæ˜¯ä¾é  .inter æ–‡ä»¶çš„å¯¹é½ã€‚
    # 
    # ç­‰ç­‰ï¼Œå¦‚æœ Script 2 åªæ˜¯ä¸ºäº†ç”Ÿæˆ RecBole æ ¼å¼çš„ KG æ–‡ä»¶ (.kg, .link)ï¼Œ
    # é‚£ä¹ˆæˆ‘ä»¬ç”Ÿæˆåˆ° dataset/MOOCCubeX_KG_Only ä¸‹é¢å³å¯ã€‚
    
    # 5. ç”Ÿæˆ RecBole æ ‡å‡† KG æ–‡ä»¶ (å¯é€‰ï¼Œç”¨äº KG å¢å¼ºæ¨¡å‹)
    # æ ¼å¼: head_id:token    relation_id:token    tail_id:token
    kg_inter_file = os.path.join(OUTPUT_DIR, 'MOOCCubeX_KG_Only.kg')
    
    kg_triplets = []
    # å‡è®¾å…³ç³»éƒ½æ˜¯ "has_concept" (relation_id=1)
    for item, concepts in filtered_kg.items():
        iid = str(item)
        for c in concepts:
            kg_triplets.append([iid, '1', str(c)])
            
    df_kg = pd.DataFrame(kg_triplets, columns=['head_id:token', 'relation_id:token', 'tail_id:token'])
    df_kg.to_csv(kg_inter_file, sep='\t', index=False)
    print(f"   âœ… RecBole KG æ–‡ä»¶å·²ç”Ÿæˆ: {kg_inter_file}")
    
    # 6. åŒæ—¶å¤åˆ¶ .inter æ–‡ä»¶åˆ° KG_Only ç›®å½•ï¼Œæ–¹ä¾¿è·‘æ¶ˆèå®éªŒ
    shutil.copy(INTER_PATH, os.path.join(OUTPUT_DIR, 'MOOCCubeX_KG_Only.inter'))
    print(f"   âœ… å·²åŒæ­¥ .inter æ–‡ä»¶åˆ°: {OUTPUT_DIR}")

import shutil

if __name__ == "__main__":
    generate_kg_subset()