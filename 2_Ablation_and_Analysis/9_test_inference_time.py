# =============================================================================
# â±ï¸ Script 9: Measure Inference Latency (Fixed Warmup)
# ä¿®å¤: å°†é¢„çƒ­æ¬¡æ•°ä» 10 é™ä½åˆ° 2ï¼Œé˜²æ­¢è·³è¿‡æ‰€æœ‰æµ‹è¯•æ•°æ®
# =============================================================================

import sys
import os
import time
import numpy as np
import torch
import functools

# --- ç¯å¢ƒè¡¥ä¸ ---
patch_map = {'float_': np.float64, 'int_': np.int64, 'bool_': bool, 'complex_': np.complex128, 'object_': object, 'unicode_': np.str_, 'string_': np.bytes_, 'str_': np.str_, 'float': float, 'int': int}
for alias, target in patch_map.items():
    if not hasattr(np, alias): setattr(np, alias, target)

_original_load = torch.load
torch.load = functools.partial(_original_load, weights_only=False)

from recbole.config import Config
from recbole.data import create_dataset, data_preparation
from recbole.model.sequential_recommender import SASRec

sys.path.append(os.path.join(os.getcwd(), 'src')) 
try:
    from model_kgnn import Gated_KG_SASRec
except:
    pass

def measure_time(model, test_data, device, model_name="Model"):
    model.eval()
    latencies = []
    
    # è·å–æµ‹è¯•é›†æ€» Batch æ•°
    total_batches = len(test_data)
    # åŠ¨æ€è°ƒæ•´é¢„çƒ­æ¬¡æ•°ï¼šå¦‚æœæ•°æ®å¾ˆå°‘ï¼Œå°±åªé¢„çƒ­ 1 æ¬¡ï¼Œå¦åˆ™é¢„çƒ­ 2 æ¬¡
    warmup_steps = 1 if total_batches < 5 else 2
    
    print(f"\nğŸš€ å¼€å§‹æµ‹è¯• {model_name} (Total Batches: {total_batches})...")
    
    with torch.no_grad():
        for i, batch_data in enumerate(test_data):
            interaction = batch_data[0].to(device)
            
            # 1. é¢„çƒ­
            if i < warmup_steps:
                _ = model.full_sort_predict(interaction)
                continue
            
            # 2. ç²¾ç¡®è®¡æ—¶
            start_event = torch.cuda.Event(enable_timing=True)
            end_event = torch.cuda.Event(enable_timing=True)
            
            start_event.record()
            _ = model.full_sort_predict(interaction)
            end_event.record()
            
            torch.cuda.synchronize()
            
            elapsed_time_ms = start_event.elapsed_time(end_event)
            
            # è·å–å½“å‰ Batch çš„ç”¨æˆ·æ•°
            try:
                batch_users = interaction.user_id.size(0)
            except:
                batch_users = interaction[0].size(0)

            latencies.append(elapsed_time_ms / batch_users)
            
            # æµ‹ 50 ä¸ª Batch å°±å¤Ÿç¨³å®šäº†
            if i >= (warmup_steps + 50): break
    
    if len(latencies) == 0:
        print("âŒ é”™è¯¯: æ²¡æœ‰æ”¶é›†åˆ°è€—æ—¶æ•°æ®ï¼Œè¯·æ£€æŸ¥æµ‹è¯•é›†æ˜¯å¦ä¸ºç©ºï¼")
        return 0.0

    avg_latency = np.mean(latencies)
    throughput = 1000 / avg_latency if avg_latency > 0 else 0
    print(f"   âœ… å¹³å‡æ¨ç†å»¶è¿Ÿ (Latency): {avg_latency:.4f} ms/user")
    print(f"   âœ… ååé‡ (Throughput):    {throughput:.2f} users/sec")
    return avg_latency

if __name__ == '__main__':
    # 1. å‡†å¤‡é…ç½®
    config_dict = {
        'use_gpu': True, 'gpu_id': 0, 'state': 'INFO',
        'eval_args': {'split': {'LS': 'valid_and_test'}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'},
        'topk': [10],
        'loss_type': 'BPR',
        'load_col': {'inter': ['user_id', 'item_id', 'timestamp']}, 
        'train_neg_sample_args': {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}
    }
    
    config = Config(model='SASRec', dataset='MOOCCubeX', config_dict=config_dict)
    dataset = create_dataset(config)
    _, _, test_data = data_preparation(config, dataset)
    
    # 2. åˆå§‹åŒ–æ¨¡å‹ç”¨äºæµ‹é€Ÿ (éšæœºæƒé‡å³å¯ï¼Œä¸å½±å“è®¡ç®—å›¾ç»“æ„å’Œé€Ÿåº¦)
    print("ğŸ”§ åˆå§‹åŒ– SASRec ç”¨äºæµ‹é€Ÿ...")
    model_s = SASRec(config, test_data.dataset).to(config['device'])
    t_sasrec = measure_time(model_s, test_data, config['device'], "SASRec")
    
    try:
        print("ğŸ”§ åˆå§‹åŒ– K-GNN ç”¨äºæµ‹é€Ÿ...")
        n_entities = dataset.item_num 
        # æ„é€ ä¸€ä¸ªå‡çš„ KG çŸ©é˜µç”¨äºå ä½ï¼Œä¿è¯æ¨¡å‹èƒ½è·‘é€š
        kg_matrix = torch.zeros((n_entities, 5), dtype=torch.long).to(config['device'])
        model_k = Gated_KG_SASRec(config, test_data.dataset, kg_matrix, n_entities).to(config['device'])
        
        t_kgnn = measure_time(model_k, test_data, config['device'], "K-GNN")
        
        if t_sasrec > 0:
            overhead = (t_kgnn - t_sasrec) / t_sasrec * 100
            print(f"\nğŸ’¡ ç»“è®º: K-GNN é¢å¤–å¼€é”€ä»…ä¸º {overhead:.2f}%")
            
    except Exception as e:
        print(f"\nâš ï¸ è·³è¿‡ K-GNN æµ‹è¯• (éœ€è¦ model_kgnn.py): {e}")